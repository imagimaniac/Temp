{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK-JumUDjrjY"
   },
   "source": [
    "<center>\n",
    "<h1> Assignment: Data Preprocessing and Modeling</h1>\n",
    "<hr>\n",
    "<h2>UFO Sighting Data Exploration</h2>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import dataset \"ufo_sightings_large.csv\" in pandas (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oK1PTSxbjrjt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BwJL_f4Vjrj5",
    "outputId": "067b3983-be67-4bf4-c94d-044f470d1b92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/3/2011 19:21</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2004 19:05</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/25/2009 21:00</td>\n",
       "      <td>coon rapids</td>\n",
       "      <td>mn</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
       "      <td>12/12/2009</td>\n",
       "      <td>45.1200000</td>\n",
       "      <td>-93.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/21/2002 05:45</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/19/2010 12:55</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date              city state country      type    seconds  \\\n",
       "0   11/3/2011 19:21         woodville    wi      us   unknown  1209600.0   \n",
       "1   10/3/2004 19:05         cleveland    oh      us    circle       30.0   \n",
       "2   9/25/2009 21:00       coon rapids    mn      us     cigar        0.0   \n",
       "3  11/21/2002 05:45          clemmons    nc      us  triangle      300.0   \n",
       "4   8/19/2010 12:55  calgary (canada)    ab      ca      oval        0.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "2              NaN  Green&#44 red&#44 and blue pulses of light tha...   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "\n",
       "     recorded         lat        long  \n",
       "0  12/12/2011  44.9530556  -92.291111  \n",
       "1  10/27/2004  41.4994444  -81.695556  \n",
       "2  12/12/2009  45.1200000  -93.287500  \n",
       "3  12/23/2002  36.0213889  -80.382222  \n",
       "4   8/24/2010   51.083333 -114.083333  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo = pd.read_csv('ufo_sightings_large.csv')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking column types & Converting Column types (10 points)\n",
    "Take a look at the UFO dataset's column types using the dtypes attribute. Please convert the column types to the proper types.\n",
    "For example, the date column, which can be transformed into the datetime type. \n",
    "That will make our feature engineering efforts easier later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ql0JX801jrj_",
    "outputId": "1da7fe6a-1907-4a85-bb3b-5d85c42ecb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               object\n",
      "city               object\n",
      "state              object\n",
      "country            object\n",
      "type               object\n",
      "seconds           float64\n",
      "length_of_time     object\n",
      "desc               object\n",
      "recorded           object\n",
      "lat                object\n",
      "long              float64\n",
      "dtype: object\n",
      "seconds           float64\n",
      "date       datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check type of column inputs\n",
    "print(ufo.dtypes)\n",
    "\n",
    "# Convert the type of seconds to float type\n",
    "ufo['seconds'] = ufo['seconds'].astype(float)\n",
    "\n",
    "# Change the type of  date column to datetime\n",
    "ufo['date'] = pd.to_datetime(ufo['date'])\n",
    "\n",
    "# Check type of seconds and date column inputs\n",
    "print(ufo[['seconds', 'date']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dropping missing data (10 points)\n",
    "Let's remove some of the rows where certain columns have missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vSY8YJMfjrkM",
    "outputId": "956d6bd9-b56b-4af1-9c74-c15c488f840a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_of_time    143\n",
      "state             419\n",
      "type              159\n",
      "dtype: int64\n",
      "(4283, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in the length_of_time, state, and type columns\n",
    "\n",
    "print(ufo[['length_of_time', 'state', 'type']].isnull().sum())\n",
    "\n",
    "# Keep only non-null rows in selected columns\n",
    "ufo_no_missing = ufo[ufo['length_of_time'].notnull() &\n",
    "                     ufo['state'].notnull() & \n",
    "                     ufo['type'].notnull()]\n",
    "\n",
    "# Print new shape of the refined dataset\n",
    "print(ufo_no_missing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting numbers from strings (10 points)\n",
    "The <b>length_of_time</b> column in the UFO dataset is a text field that has the number of \n",
    "minutes within the string. \n",
    "Here, you'll extract that number from that text field using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wuTkKeSjjrkW",
    "outputId": "7d3c0c6c-f86b-4347-df4d-b528127a10bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    length_of_time  minutes\n",
      "0  about 5 minutes      NaN\n",
      "1       10 minutes     10.0\n",
      "2        2 minutes      2.0\n",
      "3        2 minutes      2.0\n",
      "4        5 minutes      5.0\n",
      "5       10 minutes     10.0\n",
      "6        5 minutes      5.0\n",
      "7        5 minutes      5.0\n",
      "8        5 minutes      5.0\n",
      "9          1minute      1.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "ufo = pd.read_csv('ufo_sample.csv')\n",
    "\n",
    "# Change the column type of seconds to float\n",
    "ufo['seconds'] = ufo['seconds'].astype(float)\n",
    "\n",
    "# Change the type of  date column to datetime\n",
    "ufo['date'] = pd.to_datetime(ufo['date'])\n",
    "\n",
    "def return_minutes(time_string):\n",
    "    # Use \\d+ to grab any n number of  digits\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    num = re.match(pattern, time_string)  # Use match  on the pattern and column\n",
    "    if num is not None:\n",
    "        return int(num.group(0))\n",
    "    \n",
    "# Extract the numerical datafrom length_of_time\n",
    "ufo['minutes'] = ufo['length_of_time'].apply(lambda row: return_minutes(row))\n",
    "\n",
    "# check head of both columns again\n",
    "print(ufo[['length_of_time', 'minutes']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identifying features for standardization (10 points)\n",
    "In this section, you'll investigate the variance of columns in the UFO dataset to \n",
    "determine which features should be standardized. You can log normlize the high variance column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tOtYt_8qjrkd",
    "outputId": "06d64802-e145-4377-fd95-c9dc32ca8679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds    424087.417474\n",
      "minutes       117.546372\n",
      "dtype: float64\n",
      "1.1223923881183004\n"
     ]
    }
   ],
   "source": [
    "# look for variance of the seconds and minutes two columns\n",
    "print(ufo[['seconds', 'minutes']].var())\n",
    "\n",
    "# Apply Log normalize the seconds column\n",
    "ufo['seconds_log'] = np.log(ufo['seconds'])\n",
    "\n",
    "# Print out the variance of  newly added seconds_log column from above step\n",
    "print(ufo['seconds_log'].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Encoding categorical variables (20 points)\n",
    "There are couple of columns in the UFO dataset that need to be encoded before they can be \n",
    "modeled through scikit-learn. \n",
    "You'll do that transformation here, <b>using both binary and one-hot encoding methods</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aA_1Cye-jrkj",
    "outputId": "c363db3f-e6e0-4be1-d064-f0796a99858a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Encode 'us' values as 1 whereas others as 0\n",
    "ufo['country_enc'] = ufo['country'].apply(lambda x: 1 if x == 'us' else 0)\n",
    "\n",
    "# Print number of unique values in type column\n",
    "print(len(ufo['type'].unique()))\n",
    "\n",
    "# Use Getdummies to get one-hot encoded set of type column values\n",
    "type_set = pd.get_dummies(ufo['type'])\n",
    "\n",
    "# Concatenate this set back to original ufo DataFrame created in first place\n",
    "ufo = pd.concat([ufo, type_set], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LhXesZ7Wjrkn",
    "outputId": "bbeb82ff-4eef-4e6c-98f7-153abbdcff3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "                 date  month  year\n",
      "0 2002-11-21 05:45:00     11  2002\n",
      "1 2012-06-16 23:00:00      6  2012\n",
      "2 2013-06-09 00:00:00      6  2013\n",
      "3 2013-04-26 23:27:00      4  2013\n",
      "4 2013-09-13 20:30:00      9  2013\n"
     ]
    }
   ],
   "source": [
    "# Look at the type of date column\n",
    "print(ufo['date'].dtypes)\n",
    "\n",
    "# Extract month from the date column\n",
    "ufo['month'] = ufo['date'].apply(lambda date: date.month)\n",
    "\n",
    "# Extract the year from the date column\n",
    "ufo['year'] = ufo['date'].apply(lambda date: date.year)\n",
    "\n",
    "# Check new head of all three columns\n",
    "print(ufo[['date', 'month', 'year']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text vectorization (10 points)\n",
    "Let's transform the <b>desc</b> column in the UFO dataset into tf/idf vectors, \n",
    "since there's likely something we can learn from this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AIsM5o-Ojrkq",
    "outputId": "c5db91fc-6964-4303-fb1b-6ee871c43fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    It was a large&#44 triangular shaped flying ob...\n",
      "1    Dancing lights that would fly around and then ...\n",
      "2    Brilliant orange light or chinese lantern at o...\n",
      "3    Bright red light moving north to north west fr...\n",
      "4    North-east moving south-west. First 7 or so li...\n",
      "Name: desc, dtype: object\n",
      "(1866, 3422)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(ufo['desc'].head()) # Look at the head of the desc field\n",
    "\n",
    "vec = TfidfVectorizer()   # Create the tfidf vectorizer object\n",
    "\n",
    "desc_tfidf = vec.fit_transform(ufo['desc']) # Use vec's fit_transform on the desc\n",
    "\n",
    "print(desc_tfidf.shape) # Check the shape of  desc after above operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Selecting the ideal dataset (10 points)\n",
    "Let's get rid of some of the unnecessary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L_EFNR3pjrku"
   },
   "outputs": [],
   "source": [
    "def return_weights(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
    "    '''\n",
    "    This will help transform the zipped dict into a series format\n",
    "    '''\n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    '''\n",
    "    This helps to sort the series to pull out top weighted words\n",
    "    '''\n",
    "        zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    return [original_vocab[i] for i in zipped_index]\n",
    "\n",
    "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "        '''\n",
    "        This calls the function from the previous exercise, \n",
    "        and extend the list we're creating\n",
    "        '''\n",
    "        try:\n",
    "            filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
    "            filter_list.extend(filtered)\n",
    "        except:\n",
    "            pass\n",
    "    return set(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WuTtrt3Vjrkw"
   },
   "outputs": [],
   "source": [
    "vocab_csv = pd.read_csv('vocab_ufo.csv', index_col=0).to_dict()\n",
    "vocab = vocab_csv['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FxFEvw6djrkx",
    "outputId": "6f1091ad-f826-4c02-dc63-86691076cfc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              seconds  seconds_log   minutes\n",
      "seconds      1.000000     0.853371  0.980341\n",
      "seconds_log  0.853371     1.000000  0.824493\n",
      "minutes      0.980341     0.824493  1.000000\n"
     ]
    }
   ],
   "source": [
    "# See the Correlation between the seconds, seconds_log, and minutes columns\n",
    "print(ufo[['seconds', 'seconds_log', 'minutes']].corr())\n",
    "\n",
    "# Define a list of features to drop\n",
    "to_drop = ['city', 'country', 'date', 'desc', 'lat', \n",
    "           'length_of_time', 'seconds', 'minutes', 'long', 'state', 'recorded']\n",
    "\n",
    "# Drop those features listed above\n",
    "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
    "\n",
    "# Let's also filter some words out of the text vector we created\n",
    "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "J0CyVh81jrk0",
    "outputId": "5dc0c99a-3086-4110-9543-4ae97712cad3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>seconds_log</th>\n",
       "      <th>country_enc</th>\n",
       "      <th>changing</th>\n",
       "      <th>chevron</th>\n",
       "      <th>cigar</th>\n",
       "      <th>circle</th>\n",
       "      <th>cone</th>\n",
       "      <th>cross</th>\n",
       "      <th>cylinder</th>\n",
       "      <th>...</th>\n",
       "      <th>light</th>\n",
       "      <th>other</th>\n",
       "      <th>oval</th>\n",
       "      <th>rectangle</th>\n",
       "      <th>sphere</th>\n",
       "      <th>teardrop</th>\n",
       "      <th>triangle</th>\n",
       "      <th>unknown</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triangle</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>light</td>\n",
       "      <td>6.396930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>light</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>light</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sphere</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>unknown</td>\n",
       "      <td>7.901007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>oval</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>changing</td>\n",
       "      <td>5.192957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>circle</td>\n",
       "      <td>5.192957</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>other</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1866 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type  seconds_log  country_enc  changing  chevron  cigar  circle  \\\n",
       "0     triangle     5.703782            1         0        0      0       0   \n",
       "1        light     6.396930            1         0        0      0       0   \n",
       "2        light     4.787492            0         0        0      0       0   \n",
       "3        light     4.787492            1         0        0      0       0   \n",
       "4       sphere     5.703782            1         0        0      0       0   \n",
       "...        ...          ...          ...       ...      ...    ...     ...   \n",
       "1861   unknown     7.901007            1         0        0      0       0   \n",
       "1862      oval     5.703782            1         0        0      0       0   \n",
       "1863  changing     5.192957            1         1        0      0       0   \n",
       "1864    circle     5.192957            1         0        0      0       1   \n",
       "1865     other     4.094345            1         0        0      0       0   \n",
       "\n",
       "      cone  cross  cylinder  ...  light  other  oval  rectangle  sphere  \\\n",
       "0        0      0         0  ...      0      0     0          0       0   \n",
       "1        0      0         0  ...      1      0     0          0       0   \n",
       "2        0      0         0  ...      1      0     0          0       0   \n",
       "3        0      0         0  ...      1      0     0          0       0   \n",
       "4        0      0         0  ...      0      0     0          0       1   \n",
       "...    ...    ...       ...  ...    ...    ...   ...        ...     ...   \n",
       "1861     0      0         0  ...      0      0     0          0       0   \n",
       "1862     0      0         0  ...      0      0     1          0       0   \n",
       "1863     0      0         0  ...      0      0     0          0       0   \n",
       "1864     0      0         0  ...      0      0     0          0       0   \n",
       "1865     0      0         0  ...      0      1     0          0       0   \n",
       "\n",
       "      teardrop  triangle  unknown  month  year  \n",
       "0            0         1        0     11  2002  \n",
       "1            0         0        0      6  2012  \n",
       "2            0         0        0      6  2013  \n",
       "3            0         0        0      4  2013  \n",
       "4            0         0        0      9  2013  \n",
       "...        ...       ...      ...    ...   ...  \n",
       "1861         0         0        1      8  2002  \n",
       "1862         0         0        0      7  2013  \n",
       "1863         0         0        0     11  2008  \n",
       "1864         0         0        0      6  1998  \n",
       "1865         0         0        0     12  2005  \n",
       "\n",
       "[1866 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tYlmi5KSjrk1"
   },
   "outputs": [],
   "source": [
    "X = ufo_dropped.drop(['type', 'country_enc'], axis=1)\n",
    "y = ufo_dropped['country_enc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Split the X and y using train_test_split, setting stratify = y (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cykFTmKPjrk3",
    "outputId": "ef2c6080-58f9-4d3c-f91f-7a6b5d06b30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['seconds_log', 'changing', 'chevron', 'cigar', 'circle', 'cone',\n",
      "       'cross', 'cylinder', 'diamond', 'disk', 'egg', 'fireball', 'flash',\n",
      "       'formation', 'light', 'other', 'oval', 'rectangle', 'sphere',\n",
      "       'teardrop', 'triangle', 'unknown', 'month', 'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DsLD1bvDjrk4",
    "outputId": "2c1c7287-95d1-4d92-c699-d56422f3ec73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8779443254817987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Split X and y sets \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of knn on the test sets\n",
    "print(knn.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Fit knn to the training sets and print the score of knn on the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DWJjewQ4jrk6"
   },
   "outputs": [],
   "source": [
    "y = ufo_dropped['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G8dpILi8jrk7",
    "outputId": "98f913be-7499-4d90-de43-552c458c98ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22055674518201285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Use the list of filtered words to filter the text vector as follows\n",
    "filtered_text = desc_tfidf[:, list(filtered_words)]\n",
    "\n",
    "# Split X and y sets \n",
    "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
    "\n",
    "# Fit nb to the training sets\n",
    "nb.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of nb on the test sets\n",
    "print(nb.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "UFO_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
